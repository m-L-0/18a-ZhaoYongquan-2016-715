{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_label), (test_data, test_label) =\\\n",
    "    tf.keras.datasets.boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404, 13)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   0, train loss 130.3410, val loss 766.0109\n",
      "epoch   1, train loss 148.7038, val loss 99.0436\n",
      "epoch   2, train loss 96.9762, val loss 103.2786\n",
      "epoch   3, train loss 103.7976, val loss 99.3358\n",
      "epoch   4, train loss 111.8239, val loss 95.7553\n",
      "epoch   5, train loss 114.7866, val loss 97.2887\n",
      "epoch   6, train loss 76.4997, val loss 95.5522\n",
      "epoch   7, train loss 152.3408, val loss 98.2338\n",
      "epoch   8, train loss 86.2236, val loss 94.5412\n",
      "epoch   9, train loss 90.5598, val loss 97.6153\n",
      "epoch  10, train loss 73.4483, val loss 93.5682\n",
      "epoch  11, train loss 72.2662, val loss 94.4074\n",
      "epoch  12, train loss 25.2067, val loss 93.3320\n",
      "epoch  13, train loss 82.9645, val loss 91.7699\n",
      "epoch  14, train loss 100.7839, val loss 93.2040\n",
      "epoch  15, train loss 105.0298, val loss 92.3122\n",
      "epoch  16, train loss 136.0706, val loss 91.4519\n",
      "epoch  17, train loss 96.1736, val loss 89.8437\n",
      "epoch  18, train loss 63.1567, val loss 90.3711\n",
      "epoch  19, train loss 103.6810, val loss 94.7700\n",
      "epoch  20, train loss 100.9218, val loss 90.3020\n",
      "epoch  21, train loss 69.4953, val loss 85.7353\n",
      "epoch  22, train loss 96.9814, val loss 90.3378\n",
      "epoch  23, train loss 111.5885, val loss 91.0515\n",
      "epoch  24, train loss 97.1144, val loss 89.2146\n",
      "epoch  25, train loss 71.0782, val loss 94.0248\n",
      "epoch  26, train loss 97.0107, val loss 85.1079\n",
      "epoch  27, train loss 117.3743, val loss 89.4283\n",
      "epoch  28, train loss 111.4043, val loss 92.4623\n",
      "epoch  29, train loss 113.7311, val loss 88.2802\n",
      "epoch  30, train loss 69.4568, val loss 86.2361\n",
      "epoch  31, train loss 110.0074, val loss 90.8971\n",
      "epoch  32, train loss 52.4863, val loss 89.9488\n",
      "epoch  33, train loss 84.6126, val loss 91.5659\n",
      "epoch  34, train loss 69.1040, val loss 89.3373\n",
      "epoch  35, train loss 72.5961, val loss 89.8579\n",
      "epoch  36, train loss 65.4214, val loss 89.9939\n",
      "epoch  37, train loss 105.8956, val loss 87.8584\n",
      "epoch  38, train loss 93.4665, val loss 89.7660\n",
      "epoch  39, train loss 107.5754, val loss 87.2790\n",
      "epoch  40, train loss 95.6571, val loss 86.8072\n",
      "epoch  41, train loss 65.8204, val loss 89.3913\n",
      "epoch  42, train loss 117.6180, val loss 85.6761\n",
      "epoch  43, train loss 94.8045, val loss 86.0262\n",
      "epoch  44, train loss 92.4144, val loss 90.4956\n",
      "epoch  45, train loss 120.9586, val loss 88.7177\n",
      "epoch  46, train loss 39.2978, val loss 89.9465\n",
      "epoch  47, train loss 72.9449, val loss 90.5132\n",
      "epoch  48, train loss 71.6604, val loss 90.0615\n",
      "epoch  49, train loss 119.0815, val loss 90.1766\n",
      "epoch  50, train loss 90.3385, val loss 83.2472\n",
      "epoch  51, train loss 101.9321, val loss 88.2169\n",
      "epoch  52, train loss 66.3939, val loss 86.9644\n",
      "epoch  53, train loss 76.5843, val loss 89.4610\n",
      "epoch  54, train loss 119.5207, val loss 82.3105\n",
      "epoch  55, train loss 52.8875, val loss 87.9699\n",
      "epoch  56, train loss 119.7874, val loss 89.9890\n",
      "epoch  57, train loss 78.0920, val loss 88.2847\n",
      "epoch  58, train loss 91.5462, val loss 89.0544\n",
      "epoch  59, train loss 70.0378, val loss 89.2691\n",
      "epoch  60, train loss 96.8737, val loss 90.2637\n",
      "epoch  61, train loss 95.8665, val loss 89.5100\n",
      "epoch  62, train loss 83.6157, val loss 90.1855\n",
      "epoch  63, train loss 160.4722, val loss 87.5353\n",
      "epoch  64, train loss 85.2584, val loss 89.0947\n",
      "epoch  65, train loss 76.0396, val loss 92.0622\n",
      "epoch  66, train loss 42.7878, val loss 86.9294\n",
      "epoch  67, train loss 61.4588, val loss 86.1358\n",
      "epoch  68, train loss 124.9659, val loss 88.0822\n",
      "epoch  69, train loss 87.8342, val loss 86.6397\n",
      "epoch  70, train loss 68.4588, val loss 88.5819\n",
      "epoch  71, train loss 107.1170, val loss 88.5665\n",
      "epoch  72, train loss 69.6071, val loss 88.3930\n",
      "epoch  73, train loss 57.1173, val loss 89.4243\n",
      "epoch  74, train loss 60.4890, val loss 86.7819\n",
      "epoch  75, train loss 76.8588, val loss 88.1267\n",
      "epoch  76, train loss 51.9570, val loss 89.1522\n",
      "epoch  77, train loss 78.9826, val loss 88.1404\n",
      "epoch  78, train loss 102.2506, val loss 89.4565\n",
      "epoch  79, train loss 114.5437, val loss 90.0116\n",
      "epoch  80, train loss 91.0079, val loss 89.3115\n",
      "epoch  81, train loss 54.3193, val loss 87.8587\n",
      "epoch  82, train loss 135.3627, val loss 88.3775\n",
      "epoch  83, train loss 41.2760, val loss 83.9236\n",
      "epoch  84, train loss 83.9699, val loss 90.2989\n",
      "epoch  85, train loss 48.0997, val loss 88.8730\n",
      "epoch  86, train loss 49.6268, val loss 86.1287\n",
      "epoch  87, train loss 89.0829, val loss 85.9489\n",
      "epoch  88, train loss 45.5737, val loss 89.4383\n",
      "epoch  89, train loss 60.4757, val loss 87.5371\n",
      "epoch  90, train loss 135.8242, val loss 84.9866\n",
      "epoch  91, train loss 116.8660, val loss 87.7693\n",
      "epoch  92, train loss 65.2697, val loss 90.1663\n",
      "epoch  93, train loss 76.1730, val loss 87.2302\n",
      "epoch  94, train loss 60.4679, val loss 84.5396\n",
      "epoch  95, train loss 114.2752, val loss 89.9690\n",
      "epoch  96, train loss 63.2586, val loss 88.6730\n",
      "epoch  97, train loss 80.6022, val loss 83.3341\n",
      "epoch  98, train loss 134.5642, val loss 90.5653\n",
      "epoch  99, train loss 81.9608, val loss 88.6190\n",
      "epoch 100, train loss 75.9285, val loss 87.3329\n",
      "epoch 101, train loss 121.7573, val loss 88.1826\n",
      "epoch 102, train loss 146.3061, val loss 85.2418\n",
      "epoch 103, train loss 91.6994, val loss 89.7802\n",
      "epoch 104, train loss 106.0168, val loss 86.8076\n",
      "epoch 105, train loss 115.9584, val loss 86.0882\n",
      "epoch 106, train loss 94.9698, val loss 86.9945\n",
      "epoch 107, train loss 97.5838, val loss 85.9965\n",
      "epoch 108, train loss 67.7650, val loss 84.2863\n",
      "epoch 109, train loss 101.3624, val loss 85.5024\n",
      "epoch 110, train loss 106.7582, val loss 85.9687\n",
      "epoch 111, train loss 154.2930, val loss 89.3597\n",
      "epoch 112, train loss 71.8288, val loss 88.7016\n",
      "epoch 113, train loss 117.7214, val loss 87.7377\n",
      "epoch 114, train loss 109.2184, val loss 87.7731\n",
      "epoch 115, train loss 79.6434, val loss 85.1541\n",
      "epoch 116, train loss 86.1582, val loss 86.3031\n",
      "epoch 117, train loss 74.9066, val loss 88.5129\n",
      "epoch 118, train loss 72.4661, val loss 88.0281\n",
      "epoch 119, train loss 104.8017, val loss 89.3949\n",
      "epoch 120, train loss 64.9927, val loss 87.9488\n",
      "epoch 121, train loss 102.3401, val loss 85.9898\n",
      "epoch 122, train loss 107.7489, val loss 89.4761\n",
      "epoch 123, train loss 83.5898, val loss 84.9298\n",
      "epoch 124, train loss 65.1997, val loss 85.1794\n",
      "epoch 125, train loss 68.2644, val loss 88.3205\n",
      "epoch 126, train loss 72.7627, val loss 86.2542\n",
      "epoch 127, train loss 72.3779, val loss 87.1306\n",
      "epoch 128, train loss 67.1880, val loss 88.8217\n",
      "epoch 129, train loss 127.4749, val loss 86.9922\n",
      "epoch 130, train loss 85.5952, val loss 88.6888\n",
      "epoch 131, train loss 39.5427, val loss 87.2782\n",
      "epoch 132, train loss 108.0067, val loss 82.3953\n",
      "epoch 133, train loss 86.7161, val loss 87.9532\n",
      "epoch 134, train loss 100.9792, val loss 84.6085\n",
      "epoch 135, train loss 76.2202, val loss 89.4186\n",
      "epoch 136, train loss 95.0746, val loss 88.5565\n",
      "epoch 137, train loss 84.1935, val loss 89.0381\n",
      "epoch 138, train loss 82.1453, val loss 87.9500\n",
      "epoch 139, train loss 99.4310, val loss 87.5667\n",
      "epoch 140, train loss 58.1619, val loss 89.5761\n",
      "epoch 141, train loss 126.3928, val loss 80.6456\n",
      "epoch 142, train loss 103.2829, val loss 90.1673\n",
      "epoch 143, train loss 122.0411, val loss 88.7946\n",
      "epoch 144, train loss 108.3584, val loss 86.5371\n",
      "epoch 145, train loss 112.7515, val loss 86.7799\n",
      "epoch 146, train loss 93.4952, val loss 87.7848\n",
      "epoch 147, train loss 130.7758, val loss 89.0389\n",
      "epoch 148, train loss 85.5971, val loss 88.6909\n",
      "epoch 149, train loss 62.0223, val loss 85.5490\n",
      "epoch 150, train loss 64.0346, val loss 84.2610\n",
      "epoch 151, train loss 114.2865, val loss 86.1063\n",
      "epoch 152, train loss 63.6537, val loss 85.5109\n",
      "epoch 153, train loss 36.6259, val loss 85.5003\n",
      "epoch 154, train loss 143.0872, val loss 88.4081\n",
      "epoch 155, train loss 69.6674, val loss 87.0175\n",
      "epoch 156, train loss 117.4506, val loss 86.9394\n",
      "epoch 157, train loss 136.3137, val loss 85.9193\n",
      "epoch 158, train loss 69.6920, val loss 84.7474\n",
      "epoch 159, train loss 54.5853, val loss 88.3748\n",
      "epoch 160, train loss 88.5816, val loss 83.1395\n",
      "epoch 161, train loss 65.9098, val loss 87.6315\n",
      "epoch 162, train loss 101.0853, val loss 86.8072\n",
      "epoch 163, train loss 66.4307, val loss 86.1941\n",
      "epoch 164, train loss 88.4046, val loss 89.1007\n",
      "epoch 165, train loss 89.3789, val loss 87.7198\n",
      "epoch 166, train loss 92.0747, val loss 89.0657\n",
      "epoch 167, train loss 92.3968, val loss 84.4188\n",
      "epoch 168, train loss 39.6638, val loss 88.3099\n",
      "epoch 169, train loss 134.3723, val loss 89.1869\n",
      "epoch 170, train loss 51.7987, val loss 86.3001\n",
      "epoch 171, train loss 77.6899, val loss 86.7260\n",
      "epoch 172, train loss 70.1005, val loss 88.7475\n",
      "epoch 173, train loss 60.5973, val loss 85.7931\n",
      "epoch 174, train loss 105.9867, val loss 89.8101\n",
      "epoch 175, train loss 100.5306, val loss 85.5204\n",
      "epoch 176, train loss 49.7261, val loss 85.9470\n",
      "epoch 177, train loss 131.3408, val loss 88.3491\n",
      "epoch 178, train loss 59.4453, val loss 85.6954\n",
      "epoch 179, train loss 86.2309, val loss 88.6909\n",
      "epoch 180, train loss 65.5652, val loss 87.0470\n",
      "epoch 181, train loss 143.2124, val loss 87.9516\n",
      "epoch 182, train loss 95.8914, val loss 89.1105\n",
      "epoch 183, train loss 138.4285, val loss 84.7927\n",
      "epoch 184, train loss 134.6505, val loss 86.1742\n",
      "epoch 185, train loss 70.6777, val loss 89.2679\n",
      "epoch 186, train loss 35.7589, val loss 86.1316\n",
      "epoch 187, train loss 78.5536, val loss 85.1583\n",
      "epoch 188, train loss 86.5459, val loss 87.2915\n",
      "epoch 189, train loss 90.2025, val loss 84.9671\n",
      "epoch 190, train loss 100.8198, val loss 86.8329\n",
      "epoch 191, train loss 103.9381, val loss 87.0310\n",
      "epoch 192, train loss 117.2635, val loss 88.3808\n",
      "epoch 193, train loss 95.1366, val loss 89.3461\n",
      "epoch 194, train loss 95.9547, val loss 89.5421\n",
      "epoch 195, train loss 128.3467, val loss 87.9970\n",
      "epoch 196, train loss 79.1760, val loss 88.5199\n",
      "epoch 197, train loss 69.4916, val loss 90.5165\n",
      "epoch 198, train loss 86.2700, val loss 87.2283\n",
      "epoch 199, train loss 78.3380, val loss 88.1171\n"
     ]
    }
   ],
   "source": [
    "with tf.Graph().as_default() as g:\n",
    "    inputs = tf.placeholder(shape=[None, 13], dtype=tf.float32)\n",
    "    labels = tf.placeholder(shape=[None], dtype=tf.float32)\n",
    "    \n",
    "    h1 = tf.keras.layers.Dense(64, activation=tf.nn.relu)(inputs)\n",
    "    h2 = tf.keras.layers.Dense(16, activation=tf.nn.relu)(h1)\n",
    "    output = tf.keras.layers.Dense(1, activation=None)(h2)\n",
    "    \n",
    "    loss = tf.reduce_mean(\n",
    "        tf.keras.losses.mean_squared_error(labels, output))\n",
    "    \n",
    "    optim = tf.train.GradientDescentOptimizer(learning_rate=1e-6)\n",
    "    train_op = optim.minimize(loss)\n",
    "\n",
    "with tf.Session(graph=g) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch_size= 32\n",
    "    for epoch in range(200):\n",
    "        order = np.argsort(np.random.random(train_label.shape))\n",
    "        train_data = train_data[order]\n",
    "        train_label = train_label[order]\n",
    "        \n",
    "        res_train_losses = []\n",
    "        for i in range(train_label.shape[0] // batch_size):\n",
    "            start = i * batch_size\n",
    "            end = (i + 1) * batch_size\n",
    "            res_train_loss, _ = sess.run([loss, train_op],\n",
    "                     feed_dict={inputs: train_data[start: end],\n",
    "                                labels: train_label[start: end]})\n",
    "            res_train_losses.append(res_train_loss)\n",
    "        res_val_loss = sess.run(loss,\n",
    "                 feed_dict={inputs: test_data,\n",
    "                            labels: test_label})\n",
    "        print('epoch %3d, train loss %2.4f, val loss %2.4f' %\n",
    "              (epoch, res_train_loss, np.mean(res_train_losses)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作业\n",
    "\n",
    "1. 复现上述房价预测代码\n",
    "2. 为上述模型训练添加代价变化的`TensorBoard`摘要\n",
    "3. 导入`Fashion_MNIST`数据集并可视化\n",
    "4. 构建全连接神经网络并使用导入的数据训练分类器\n",
    "5. 尝试改进神经网络的结构与训练方法提高模型性能\n",
    "\n",
    "\n",
    "提示：可使用`tf.keras.datasets.fashion_mnist.load_data()`导入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 复现上述房价预测代码\n",
    "2. 为上述模型训练添加代价变化的TensorBoard摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data, train_label), (test_data, test_label) = tf.keras.datasets.boston_housing.load_data()\n",
    "\n",
    "with tf.Graph().as_default() as g:\n",
    "    \n",
    "    inputs = tf.placeholder(shape=[None, 13], dtype=tf.float32)\n",
    "    labels = tf.placeholder(shape=[None,], dtype=tf.float32)\n",
    "    \n",
    "    h1 = tf.keras.layers.Dense(64, activation=tf.nn.relu)(inputs)\n",
    "    h2 = tf.keras.layers.Dense(16, activation=tf.nn.relu)(h1)\n",
    "    output = tf.keras.layers.Dense(1, activation=None)(h2)\n",
    "    \n",
    "    with tf.name_scope('loss'):\n",
    "        loss = tf.reduce_mean(tf.keras.losses.mean_squared_error(labels, output))\n",
    "        val_loss_summary = tf.summary.scalar('val_loss', loss)\n",
    "\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=1e-6).minimize(loss)\n",
    "    \n",
    "\n",
    "with tf.Session(graph = g) as sess:\n",
    "\n",
    "    writer = tf.summary.FileWriter('./graphs')\n",
    "    writer.add_graph(g)\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    batch_size = 32\n",
    "    for epoch in range(200):\n",
    "        order = np.argsort(np.random.random(train_label.shape))\n",
    "        train_data = train_data[order]\n",
    "        train_label = train_label[order]\n",
    "        \n",
    "        train_num = train_label.shape[0] // batch_size\n",
    "        for i in range(train_num):\n",
    "            start = i * batch_size\n",
    "            end = (i+1) * batch_size\n",
    "            sess.run([loss, optimizer], feed_dict={\n",
    "                inputs: train_data[start: end],\n",
    "                labels: train_label[start: end]})\n",
    "            \n",
    "        res = sess.run(val_loss_summary, feed_dict={\n",
    "            inputs: test_data,\n",
    "            labels: test_label\n",
    "        })\n",
    "        writer.add_summary(res, epoch)\n",
    "        \n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用tensorboard可视化模型训练时在验证集上的损失\n",
    "\n",
    "<img src=\"val_loss.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "方法二:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\pydp\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(input_shape=(13,), units=64)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "D:\\Anaconda3\\envs\\pydp\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=16)`\n",
      "  if sys.path[0] == '':\n",
      "D:\\Anaconda3\\envs\\pydp\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=1)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 404 samples, validate on 102 samples\n",
      "Epoch 1/300\n",
      " - 0s - loss: 1120.4460 - val_loss: 102.0779\n",
      "Epoch 2/300\n",
      " - 0s - loss: 114.0900 - val_loss: 96.7795\n",
      "Epoch 3/300\n",
      " - 0s - loss: 62.5859 - val_loss: 61.0377\n",
      "Epoch 4/300\n",
      " - 0s - loss: 56.0189 - val_loss: 61.5416\n",
      "Epoch 5/300\n",
      " - 0s - loss: 56.0377 - val_loss: 60.9013\n",
      "Epoch 6/300\n",
      " - 0s - loss: 55.6384 - val_loss: 61.2203\n",
      "Epoch 7/300\n",
      " - 0s - loss: 54.5937 - val_loss: 62.3440\n",
      "Epoch 8/300\n",
      " - 0s - loss: 53.1588 - val_loss: 62.6461\n",
      "Epoch 9/300\n",
      " - 0s - loss: 51.7627 - val_loss: 61.8082\n",
      "Epoch 10/300\n",
      " - 0s - loss: 50.3707 - val_loss: 59.9144\n",
      "Epoch 11/300\n",
      " - 0s - loss: 48.9575 - val_loss: 57.7119\n",
      "Epoch 12/300\n",
      " - 0s - loss: 47.6349 - val_loss: 55.6380\n",
      "Epoch 13/300\n",
      " - 0s - loss: 46.4078 - val_loss: 54.0297\n",
      "Epoch 14/300\n",
      " - 0s - loss: 45.3495 - val_loss: 52.3146\n",
      "Epoch 15/300\n",
      " - 0s - loss: 44.3025 - val_loss: 51.0096\n",
      "Epoch 16/300\n",
      " - 0s - loss: 43.3728 - val_loss: 50.0058\n",
      "Epoch 17/300\n",
      " - 0s - loss: 42.5167 - val_loss: 48.7959\n",
      "Epoch 18/300\n",
      " - 0s - loss: 41.6834 - val_loss: 47.8202\n",
      "Epoch 19/300\n",
      " - 0s - loss: 40.9166 - val_loss: 47.0452\n",
      "Epoch 20/300\n",
      " - 0s - loss: 40.2171 - val_loss: 46.2068\n",
      "Epoch 21/300\n",
      " - 0s - loss: 39.5441 - val_loss: 45.5119\n",
      "Epoch 22/300\n",
      " - 0s - loss: 38.9022 - val_loss: 44.8863\n",
      "Epoch 23/300\n",
      " - 0s - loss: 38.3056 - val_loss: 44.2639\n",
      "Epoch 24/300\n",
      " - 0s - loss: 37.7290 - val_loss: 43.6876\n",
      "Epoch 25/300\n",
      " - 0s - loss: 37.1980 - val_loss: 43.1928\n",
      "Epoch 26/300\n",
      " - 0s - loss: 36.7400 - val_loss: 43.0357\n",
      "Epoch 27/300\n",
      " - 0s - loss: 36.3229 - val_loss: 42.7107\n",
      "Epoch 28/300\n",
      " - 0s - loss: 35.9899 - val_loss: 42.4495\n",
      "Epoch 29/300\n",
      " - 0s - loss: 35.6368 - val_loss: 42.4050\n",
      "Epoch 30/300\n",
      " - 0s - loss: 35.3356 - val_loss: 42.1998\n",
      "Epoch 31/300\n",
      " - 0s - loss: 35.0353 - val_loss: 42.0222\n",
      "Epoch 32/300\n",
      " - 0s - loss: 34.8002 - val_loss: 41.3802\n",
      "Epoch 33/300\n",
      " - 0s - loss: 34.5084 - val_loss: 41.0310\n",
      "Epoch 34/300\n",
      " - 0s - loss: 34.1948 - val_loss: 40.9417\n",
      "Epoch 35/300\n",
      " - 0s - loss: 34.0029 - val_loss: 40.9002\n",
      "Epoch 36/300\n",
      " - 0s - loss: 33.8445 - val_loss: 40.8527\n",
      "Epoch 37/300\n",
      " - 0s - loss: 33.7303 - val_loss: 40.7225\n",
      "Epoch 38/300\n",
      " - 0s - loss: 33.5744 - val_loss: 40.7523\n",
      "Epoch 39/300\n",
      " - 0s - loss: 33.4953 - val_loss: 41.0217\n",
      "Epoch 40/300\n",
      " - 0s - loss: 33.4592 - val_loss: 40.9985\n",
      "Epoch 41/300\n",
      " - 0s - loss: 33.3882 - val_loss: 40.8885\n",
      "Epoch 42/300\n",
      " - 0s - loss: 33.2890 - val_loss: 40.7340\n",
      "Epoch 43/300\n",
      " - 0s - loss: 33.2072 - val_loss: 40.8744\n",
      "Epoch 44/300\n",
      " - 0s - loss: 33.1316 - val_loss: 40.8567\n",
      "Epoch 45/300\n",
      " - 0s - loss: 33.0635 - val_loss: 40.8743\n",
      "Epoch 46/300\n",
      " - 0s - loss: 33.0058 - val_loss: 40.8689\n",
      "Epoch 47/300\n",
      " - 0s - loss: 32.9094 - val_loss: 40.9552\n",
      "Epoch 48/300\n",
      " - 0s - loss: 32.8111 - val_loss: 40.5076\n",
      "Epoch 49/300\n",
      " - 0s - loss: 32.6337 - val_loss: 40.6937\n",
      "Epoch 50/300\n",
      " - 0s - loss: 32.5234 - val_loss: 40.8737\n",
      "Epoch 51/300\n",
      " - 0s - loss: 32.5375 - val_loss: 40.9873\n",
      "Epoch 52/300\n",
      " - 0s - loss: 32.4360 - val_loss: 41.3021\n",
      "Epoch 53/300\n",
      " - 0s - loss: 32.4711 - val_loss: 41.6762\n",
      "Epoch 54/300\n",
      " - 0s - loss: 32.4764 - val_loss: 41.8861\n",
      "Epoch 55/300\n",
      " - 0s - loss: 32.4092 - val_loss: 42.0616\n",
      "Epoch 56/300\n",
      " - 0s - loss: 32.5094 - val_loss: 42.4405\n",
      "Epoch 57/300\n",
      " - 0s - loss: 32.5676 - val_loss: 42.9500\n",
      "Epoch 58/300\n",
      " - 0s - loss: 32.5834 - val_loss: 42.9000\n",
      "Epoch 59/300\n",
      " - 0s - loss: 32.5260 - val_loss: 43.3562\n",
      "Epoch 60/300\n",
      " - 0s - loss: 32.4563 - val_loss: 43.4915\n",
      "Epoch 61/300\n",
      " - 0s - loss: 32.4475 - val_loss: 43.5873\n",
      "Epoch 62/300\n",
      " - 0s - loss: 32.3936 - val_loss: 43.6070\n",
      "Epoch 63/300\n",
      " - 0s - loss: 32.3494 - val_loss: 43.6757\n",
      "Epoch 64/300\n",
      " - 0s - loss: 32.4218 - val_loss: 44.2613\n",
      "Epoch 65/300\n",
      " - 0s - loss: 32.3522 - val_loss: 44.0824\n",
      "Epoch 66/300\n",
      " - 0s - loss: 32.3921 - val_loss: 44.5753\n",
      "Epoch 67/300\n",
      " - 0s - loss: 32.3483 - val_loss: 44.6367\n",
      "Epoch 68/300\n",
      " - 0s - loss: 32.4603 - val_loss: 44.4917\n",
      "Epoch 69/300\n",
      " - 0s - loss: 32.2721 - val_loss: 44.9848\n",
      "Epoch 70/300\n",
      " - 0s - loss: 32.3042 - val_loss: 44.7033\n",
      "Epoch 71/300\n",
      " - 0s - loss: 32.2451 - val_loss: 44.9598\n",
      "Epoch 72/300\n",
      " - 0s - loss: 32.2518 - val_loss: 44.5377\n",
      "Epoch 73/300\n",
      " - 0s - loss: 32.0210 - val_loss: 44.7847\n",
      "Epoch 74/300\n",
      " - 0s - loss: 32.0998 - val_loss: 43.4207\n",
      "Epoch 75/300\n",
      " - 0s - loss: 31.4122 - val_loss: 42.5898\n",
      "Epoch 76/300\n",
      " - 0s - loss: 31.0709 - val_loss: 42.0217\n",
      "Epoch 77/300\n",
      " - 0s - loss: 30.8247 - val_loss: 41.9900\n",
      "Epoch 78/300\n",
      " - 0s - loss: 30.7716 - val_loss: 41.6370\n",
      "Epoch 79/300\n",
      " - 0s - loss: 30.6485 - val_loss: 41.8902\n",
      "Epoch 80/300\n",
      " - 0s - loss: 30.7100 - val_loss: 42.1904\n",
      "Epoch 81/300\n",
      " - 0s - loss: 30.6157 - val_loss: 42.0216\n",
      "Epoch 82/300\n",
      " - 0s - loss: 30.6055 - val_loss: 42.5096\n",
      "Epoch 83/300\n",
      " - 0s - loss: 30.6152 - val_loss: 42.3719\n",
      "Epoch 84/300\n",
      " - 0s - loss: 30.5024 - val_loss: 42.3079\n",
      "Epoch 85/300\n",
      " - 0s - loss: 30.3978 - val_loss: 42.3011\n",
      "Epoch 86/300\n",
      " - 0s - loss: 30.3905 - val_loss: 42.6650\n",
      "Epoch 87/300\n",
      " - 0s - loss: 30.3517 - val_loss: 42.4246\n",
      "Epoch 88/300\n",
      " - 0s - loss: 30.2615 - val_loss: 42.5642\n",
      "Epoch 89/300\n",
      " - 0s - loss: 30.1837 - val_loss: 42.9013\n",
      "Epoch 90/300\n",
      " - 0s - loss: 30.2783 - val_loss: 42.2692\n",
      "Epoch 91/300\n",
      " - 0s - loss: 30.0558 - val_loss: 41.5412\n",
      "Epoch 92/300\n",
      " - 0s - loss: 29.7336 - val_loss: 41.3577\n",
      "Epoch 93/300\n",
      " - 0s - loss: 29.6310 - val_loss: 41.2672\n",
      "Epoch 94/300\n",
      " - 0s - loss: 29.4574 - val_loss: 41.5136\n",
      "Epoch 95/300\n",
      " - 0s - loss: 29.4186 - val_loss: 41.1385\n",
      "Epoch 96/300\n",
      " - 0s - loss: 29.3261 - val_loss: 41.4419\n",
      "Epoch 97/300\n",
      " - 0s - loss: 29.2080 - val_loss: 41.1215\n",
      "Epoch 98/300\n",
      " - 0s - loss: 29.1446 - val_loss: 41.0837\n",
      "Epoch 00098: early stopping\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHwdJREFUeJzt3X2UHXWd5/H3t+refshj55mQRBOcLD6gAkYmDh4XZBSCruAqHMdhzHo4G88el2FGUcLuqMfd+QPPziJyzogHJYqroizowiqO4SEs7lFgQmQlPDiJiqQJJG1IQpJ+ug/f/aN+t/t2d91O0jfdHX738zrnputW1a37q1s39bm/X/2qytwdERFpPcl0F0BERKaHAkBEpEUpAEREWpQCQESkRSkARERalAJARKRFKQBERFqUAkBEpEUpAEREWlRhugswnoULF/rKlSunuxgiIq8qjz/++B/dfdHR5jupA2DlypVs3bp1uoshIvKqYmZ/OJb51AQkItKiFAAiIi1KASAi0qJO6mMAIiITUSqV6O7upr+/f7qLMqk6OjpYvnw5xWJxQq9XAIhIdLq7u5k9ezYrV67EzKa7OJPC3dm3bx/d3d2sWrVqQstQE5CIRKe/v58FCxZEu/MHMDMWLFjQVC1HASAiUYp551/T7DpGGQAvHuzjhs2/4Xc9h6e7KCIiJ60oA6Dn0AA3PbiT3//xyHQXRURa0IEDB/jqV7963K+7+OKLOXDgwCSUKF+UAZAmWbWoVNEN70Vk6jUKgEqlMu7r7r33Xrq6uiarWGNE2QuokGS5VqkqAERk6m3cuJHf/va3nHnmmRSLRWbNmsXSpUt54oknePrpp7n00kvZtWsX/f39XH311WzYsAEYvvzN4cOHWbduHe985zv5xS9+wbJly7j77rvp7Ow8oeWMMwDSrAZQrlanuSQiMt2++L+f4undr5zQZb7x1Dl84d+8qeH066+/nu3bt/PEE0/w0EMP8b73vY/t27cPddfctGkT8+fPp6+vj7e//e186EMfYsGCBSOWsWPHDm6//Xa+/vWvc/nll3PXXXdxxRVXnND1iDMAQhNQWU1AInISOOecc0b01b/pppv40Y9+BMCuXbvYsWPHmABYtWoVZ555JgBve9vbeO655054ueIMgFRNQCKSGe+X+lSZOXPm0PBDDz3E/fffzy9/+UtmzJjBeeedl9uXv729fWg4TVP6+vpOeLmiPAhcqwGU1AQkItNg9uzZHDp0KHfawYMHmTdvHjNmzODZZ5/lkUcemeLSDYuyBlDrBaQagIhMhwULFnDuuedyxhln0NnZyZIlS4amXXTRRXzta1/jLW95C6effjpr166dtnJGGQDF0AtIxwBEZLp873vfyx3f3t7OT3/609xptXb+hQsXsn379qHx11xzzQkvH0TaBJSqF5CIyFFFGQBDvYDUBCQi0lDcAaAmIBGRhqIMgFQ1ABGRo4oyAMyMQmJUdAxARKShKAMAslqAmoBERBqLNgCKaaImIBGZFhO9HDTAjTfeSG9v7wkuUb5oAyCrAagJSESm3qslAKI8EQygmJpqACIyLeovB/2e97yHxYsXc8cddzAwMMAHP/hBvvjFL3LkyBEuv/xyuru7qVQqfO5zn2PPnj3s3r2b888/n4ULF7Jly5ZJLedRA8DMNgHvB/a6+xlh3HzgB8BK4Dngcnffb9kNKr8CXAz0Av/O3beF16wH/i4s9u/d/bYTuyoj6RiAiADw043w0pMndpmnvBnWXd9wcv3loDdv3sydd97JY489hrvzgQ98gIcffpienh5OPfVUfvKTnwDZNYLmzp3LDTfcwJYtW1i4cOGJLXOOY2kC+hZw0ahxG4EH3H018EB4DrAOWB0eG4CbYSgwvgD8KXAO8AUzm9ds4cdTSHQMQESm3+bNm9m8eTNnnXUWZ599Ns8++yw7duzgzW9+M/fffz/XXnstP//5z5k7d+6Ul+2oNQB3f9jMVo4afQlwXhi+DXgIuDaM/7a7O/CImXWZ2dIw733u/jKAmd1HFiq3N70GDRRSdQMVEcb9pT4V3J3rrruOT3ziE2OmPf7449x7771cd911vPe97+Xzn//8lJZtogeBl7j7iwDh7+Iwfhmwq26+7jCu0fhJkyZGSTUAEZkG9ZeDvvDCC9m0aROHDx8G4IUXXmDv3r3s3r2bGTNmcMUVV3DNNdewbdu2Ma+dbCf6ILDljPNxxo9dgNkGsuYjXvOa10y4IMUkoaJjACIyDeovB71u3To++tGP8o53vAOAWbNm8Z3vfIedO3fymc98hiRJKBaL3HzzzQBs2LCBdevWsXTp0uk/CNzAHjNb6u4vhiaevWF8N7Cibr7lwO4w/rxR4x/KW7C73wLcArBmzZoJ78HTxHQ1UBGZNqMvB3311VePeP66172OCy+8cMzrrrrqKq666qpJLVvNRJuA7gHWh+H1wN114z9mmbXAwdBE9DPgvWY2Lxz8fW8YN2kK6gYqIjKuY+kGejvZr/eFZtZN1pvneuAOM7sSeB64LMx+L1kX0J1k3UA/DuDuL5vZfwX+Ocz3X2oHhCdLdi0gBYCISCPH0gvoLxpMuiBnXgc+2WA5m4BNx1W6JhSShJLOBBZpWe5OdmpSvLJd7sRFeymIrBuoagAiraijo4N9+/Y1vYM8mbk7+/bto6OjY8LLiPZSEGli9A7Gu/FFpLHly5fT3d1NT0/PdBdlUnV0dLB8+fIJvz7aANAxAJHWVSwWWbVq1XQX46QXcROQLgUhIjKeeANAl4MWERlXvAGQJmoCEhEZR7wBkBglnQksItJQtAGQJqZrAYmIjCPaANAdwURExhdtAGQXg1MAiIg0Em0AFJJEvYBERMYRcQCoBiAiMp5oAyDVMQARkXFFGwDFROcBiIiMJ9oASMO1gGK+GqCISDOiDYBiml0HXM1AIiL5og2ANMlWrayTwUREckUbAIWkVgNQV1ARkTzxBkBoAtKBYBGRfPEGQKgBlNQEJCKSK94ASLNVUw1ARCRftAGQDtUAdAxARCRPtAFQawJSDUBEJF+8ARCagNQLSEQkX7wBkOhEMBGR8cQfAOoFJCKSK94A0KUgRETGFW0A1C4FUdExABGRXE0FgJn9rZk9ZWbbzex2M+sws1Vm9qiZ7TCzH5hZW5i3PTzfGaavPBEr0EhRJ4KJiIxrwgFgZsuAvwbWuPsZQAp8BPgS8GV3Xw3sB64ML7kS2O/ufwJ8Ocw3aVJ1AxURGVezTUAFoNPMCsAM4EXg3cCdYfptwKVh+JLwnDD9AjOzJt+/ccGGuoEqAERE8kw4ANz9BeAfgOfJdvwHgceBA+5eDrN1A8vC8DJgV3htOcy/YPRyzWyDmW01s609PT0TLV5dLyAdAxARydNME9A8sl/1q4BTgZnAupxZaz/B837tj/l57u63uPsad1+zaNGiiRZvqAlINQARkXzNNAH9OfB7d+9x9xLwQ+DPgK7QJASwHNgdhruBFQBh+lzg5Sbef1zFVDeEEREZTzMB8Dyw1sxmhLb8C4CngS3Ah8M864G7w/A94Tlh+oM+iTfsTXVDGBGRcTVzDOBRsoO524Anw7JuAa4FPmVmO8na+G8NL7kVWBDGfwrY2ES5j6qoG8KIiIyrcPRZGnP3LwBfGDX6d8A5OfP2A5c1837HI9WlIERExhXtmcCFRN1ARUTGE28ApDoGICIynngDQE1AIiLjijcAdE9gEZFxxRsAtYvBqQlIRCRX9AFQUROQiEiuaAMgHaoBKABERPJEGwBmRpqYbggjItJAtAEAWTOQzgMQEckXfwDoGICISK64AyBN1A1URKSBuAMgMUq6IYyISK6oAyA7CKwagIhInqgDoJgmOggsItJA1AGQJqZ7AouINBB1ABRSdQMVEWkk7gBQN1ARkYaiDoA00TEAEZFGog6AYmq6IYyISANRB4C6gYqINBZ1ABSTRMcAREQaiDoA0kRNQCIijUQdAOoGKiLSWNwBoG6gIiINRR0A6gYqItJY1AFQTHVHMBGRRqIOgFRNQCIiDTUVAGbWZWZ3mtmzZvaMmb3DzOab2X1mtiP8nRfmNTO7ycx2mtmvzezsE7MKjemWkCIijTVbA/gK8E/u/nrgrcAzwEbgAXdfDTwQngOsA1aHxwbg5ibf+6gKaaKrgYqINDDhADCzOcC7gFsB3H3Q3Q8AlwC3hdluAy4Nw5cA3/bMI0CXmS2dcMmPgWoAIiKNNVMDOA3oAb5pZr8ys2+Y2Uxgibu/CBD+Lg7zLwN21b2+O4ybNIVUl4IQEWmkmQAoAGcDN7v7WcARhpt78ljOuDF7ZzPbYGZbzWxrT09PE8WDQpLonsAiIg00EwDdQLe7Pxqe30kWCHtqTTvh7966+VfUvX45sHv0Qt39Fndf4+5rFi1a1ETxdDE4EZHxTDgA3P0lYJeZnR5GXQA8DdwDrA/j1gN3h+F7gI+F3kBrgYO1pqLJUkiNkgJARCRXocnXXwV818zagN8BHycLlTvM7ErgeeCyMO+9wMXATqA3zDupCqoBiIg01FQAuPsTwJqcSRfkzOvAJ5t5v+NVSBIqVcfdMcs7BCEi0rqiPhO4kGQ7fXUFFREZK+oASNMsANQMJCIyVtQBUEyy1VNXUBGRsaIOgDRRDUBEpJGoA6CY6hiAiEgjUQdAGpqAdEloEZGxog6A4V5AOgYgIjJa3AFQawJSDUBEZIyoAyDVeQAiIg1FHQDFNFs99QISERkr6gCo1QB0HoCIyFhRB0BB5wGIiDQUdwCEJiD1AhIRGSvuAEjUC0hEpJHWCAA1AYmIjBF3AOhSECIiDUUdALVLQVR0DEBEZIyoA6Aw1A1UNQARkdHiDgDdEEZEpKG4A0A3hBERaSjyAFANQESkkagDQBeDExFpLOoAqF0MTieCiYiMFXUADN8TWMcARERGizoAavcEVjdQEZGxog6AVAeBRUQaijoAho4BKABERMZoOgDMLDWzX5nZj8PzVWb2qJntMLMfmFlbGN8enu8M01c2+95HM9QLSOcBiIiMcSJqAFcDz9Q9/xLwZXdfDewHrgzjrwT2u/ufAF8O800qXQ1URKSxpgLAzJYD7wO+EZ4b8G7gzjDLbcClYfiS8Jww/YIw/6QxM9LEdEMYEZEczdYAbgQ+C9T2sAuAA+5eDs+7gWVheBmwCyBMPxjmn1RZAKgGICIy2oQDwMzeD+x198frR+fM6scwrX65G8xsq5lt7enpmWjxhhQTo6JuoCIiYzRTAzgX+ICZPQd8n6zp50agy8wKYZ7lwO4w3A2sAAjT5wIvj16ou9/i7mvcfc2iRYuaKF5GNQARkXwTDgB3v87dl7v7SuAjwIPu/pfAFuDDYbb1wN1h+J7wnDD9QXef9D1zIU10DEBEJMdknAdwLfApM9tJ1sZ/axh/K7AgjP8UsHES3nuMQmK6FpCISI7C0Wc5Ond/CHgoDP8OOCdnnn7gshPxfsejoCYgEZFcUZ8JDFkTkC4FISIyVvwBkJjuCCYikiP6AEgTUw1ARCRH9AFQSBNdDlpEJEf8AZCYbggjIpIj/gBI1QtIRCRP/AGg8wBERHJFHwA6CCwiki/6ACimCSUdAxARGSP6AFANQEQkX/QBUEjUDVREJE8LBIC6gYqI5Ik+AFJ1AxURyRV9ABTVDVREJFf0AZAmuhqoiEie6AOgmOpqoCIieaIPAHUDFRHJF30A6I5gIiL54g+ANKGsJiARkTHiDwDVAEREcsUfADoPQEQkV/QBUOsG6q4QEBGpF30AFBIDUE8gEZFR4g+ANAsANQOJiIwUfwAkCgARkTwtEADZKqorqIjISPEHgJqARERyTTgAzGyFmW0xs2fM7CkzuzqMn29m95nZjvB3XhhvZnaTme00s1+b2dknaiXGk+ogsIhIrmZqAGXg0+7+BmAt8EkzeyOwEXjA3VcDD4TnAOuA1eGxAbi5ifc+ZsXQBKQLwomIjDThAHD3F919Wxg+BDwDLAMuAW4Ls90GXBqGLwG+7ZlHgC4zWzrhkh8j1QBERPKdkGMAZrYSOAt4FFji7i9CFhLA4jDbMmBX3cu6w7hJVTsGoPsCi4iM1HQAmNks4C7gb9z9lfFmzRk3Zq9sZhvMbKuZbe3p6Wm2eEO9gFQDEBEZqakAMLMi2c7/u+7+wzB6T61pJ/zdG8Z3AyvqXr4c2D16me5+i7uvcfc1ixYtaqZ4wHATUFk3hhcRGaGZXkAG3Ao84+431E26B1gfhtcDd9eN/1joDbQWOFhrKppMxVo3UDUBiYiMUGjitecCfwU8aWZPhHH/CbgeuMPMrgSeBy4L0+4FLgZ2Ar3Ax5t472OW6kxgEZFcEw4Ad/+/5LfrA1yQM78Dn5zo+01UMdWZwCIieaI/E1jdQEVE8kUfALoYnIhIvvgDoNYEpF5AIiIjxB8AiXoBiYjkiT8AdDVQEZFc8QeAjgGIiOSKPgBS3RBGRCRX9AGgGoCISL74AyDVeQAiInniDwA1AYmI5Io+ADqK2Sru7y1Nc0lERE4ucQaAOxx6CYDZHUXeunwu9z29Z5oLJSJycokzAPY8Bf/9dLjlfHj4v/FXp/Xy5AsH+cO+I9NdMhGRk0acATBzIbz7c2AJPPj3fPixy/hI+iA/eXLSbz8gIvKqEWcAzD4F3nUN/PsH4NO/gRV/yjXtP+Jn/+/56S6ZiMhJI84AqDf7FDjvOhZW9/GmvT/m939UM5CICLRCAACcdh6Dp5zNf0jv4adPqBYgIgKtEgBmtJ1/LSuSHnq3fX+6SyMiclJojQAA+FcXsm/26Xzw8A/Y+dLB6S6NiMi0a+am8K8uZiT/+rO87sdXsu2bH+KlRQtYPMNILIFiZ/ZIUqiUoVqCcj/0H4S+AzBwKBtXrWSPYie0z4K22TBrMcxZBnNOha4V0PUa6HotdM4Da3TLZBGR6dc6AQDMO/vfsuuXm1iybweHn3+Bg0kbncWEdh+g6AOkVKhQoJoUqFiRweIcym1z8LYlFIrttLW10V4s0GGDtFX6SEuHs3MOdmyGUu/IN2ubBXNXZKEw51SYtSQLi1lLYNYpMHtJNlxon54PQ0RaXksFAEnCiqvupVyp8n/+pYe7tnWz6+W+ocmVqlOuVilVnP5ShUOHyxweKDdc3My2lPmz2pg/p8jyzkFOa9vPa5O9LPUeFlX2MHdwD7P2vUB79zbSvn0YOReka5sFnfNhxjzomAvtc7K/HV1ZLaKza3h8++ys5lGcCW11jySdjE9LRCLXWgEQFNKEC96whAvesOSo81aqzqH+EvuODPLykUH2Hc7+7u+tDQ+w78ggzx2BX/XMY9+RmQyUXztmOSkV5vMKr2k7xGvbDrGieJBT0ldYkBxmnh9mzpFDzDx8gM7qC7RXjtBeeoVipTenRDmKM7JHW/hb7IRCJxQ7wt/64Q4odGQ1j0IHpO1QaIOkmJ04Z0kWKGkxG5cWs+eWhqCx0LRlw/PW/7U0W3ZxRvZeaVv2SAqt0STmDtUyVEpZs2GlDJVB8Eo2vlrJ5vHQnFgNTY6VEpQHsnnL/dlzGP7M6qd7ddTDAQ9/GTtcLUOpf3i5tW0FI99vaFnhfS3MV2sSLQ9m05J0eHvW1gmy70ptW9fWDc9+yMxYkD3aZ4cfLrOy71+xM/u+JLVdUfhepeG7Z0nd51T3eVUrw99Xs7Aeg9lfGDmt/js7tJ2q4XMfhGo1rFP4ng99rpXQJBweadvI/1NtM7PveaF95OdV/1617e6erWPt8/FK+I6Uw3vXrW/9dp9kLRkAxyNNjK4ZbXTNaON1i44+v7vTO1hhf+8g+4+UeLl3kAO9gxzoLWWPvkEO9Zd5tr/EY31lDg2UeKWvzKH+EocHypTq7l1cpEwXh5llfcyij9nWy0z6mUE/M22ArnSQOYVB5ng/s0sDzKyU6OwfoJNBOuilg/20M0CbD1KsDlD0QQrVAQrVgfzayGSr/afM+w9ZHypDjzDNwz9DO4BRtTKzuuXWhRE2/J/5WNZ3xI7UQ5i1ZSFpyfBO28NOvFrJ2RlXmvyQJokl2Y4rLQyXHc92SIUQ1Fa3XWph4GHnWOjIPgtseDt4dfgHgjO8Q62Uh0MCz46j9b0ctoMcszd9EC771qS+hQLgBDMzZrYXmNleYPm843utuzNQrnJ4oEzvQIXDA2WODJY5MlCmdzB73jdY4chgNr2vVOH5UoX+wQq9gxX6yxX6Biv0lyr0l6r0lbJ5+ksVBkpVBocuie20UaaNEm2UaadEalWMKml4FKhQoEKRCkl4ns2T7UgTnJQqbQkUzCkm2aNgTqcN0mllOm2AdivTZtlyiomTWDa/AYlln1eCYwaJOQnDD8PBDMOyH5tWwC2hSjr0CynbXfnQI6E6Ytit7tduWM7Qtgr/WC1pbHiJZkbiVQo+SOJlEipDtaChZVqCWyhtCBxPCrhlx5GqVqCSFEO502xeS6laAiSQhE82CZ90UqBs7VSSIhUr1L4UAFSTYni0hTJk728YbrVPIcn24eF76Jatr1u2Nesj0GrTcnKxNr7qjmebgDQxkgavsfAZ1n+2qRlJYqRJLUeqFEuvMNP6mEU/nfTR7iUK4YdJalXSUPbEK5iXsWoZowpJAQuB4uGBpZhn31ncsbSIp+14Lci8mk13B3MShn9UZ59Pgg/VMlLMK1gINUtSLEkwS7PATIpYmuLlUFsa7MXKfSSlXpJyH4mX634MVIZ/QECoKaXDtaURv/oLdbWlUFusr70tfn3+juIEUgCcRMyMjmJKRzGFWSd++dVqFjAD5SwgBuuHK9nzwUqVUrlKqTI8rlx1ylWnVK4OHSMpVapUw/hy1SlXho+f9FWdw+7hmIpTCeMr1ex1tfHVqlPx7G/Vs+a22k7HyeZ3sv8P2XCYFv5/uA9Ph+w11aHpteHheXxo2aPGMzwer1/OyOVPHQdGX768DPTlzPtq1x4eJ4IDA8c4b5XmPtMiMBeYixkUk4Q0MQqJhYqUkRgkIQiTUSFZC2mrzRP+1v8WOf/0xfzdmyZYvGOkAGghSWJ0tqV0tumg8fEaCit3qtXh0Ki6Y3U/fd2Hw2NkzaJOXejUfj3XWsWGdgyMbAbOC67RrVojgizMG95uxHLrl1MbX19+J9sZ1crgzlBQD6lrnhsdkrXwrlaz19Wvy0C5St9gVjMtVaqUKyN/FNT/CIBQC6n7XGvLMmxU4A+/t9V94LV5qlUfFfr1n63XDY/8IVH7TIdWu/6968qc/QjKfizVfmxUw/ej/jszclsOf97V8IOptr1wWNrVyWRTAIgcgyQxkjF7cpFXtyk/E9jMLjKz35jZTjPbONXvLyIimSkNADNLgX8E1gFvBP7CzN44lWUQEZHMVNcAzgF2uvvv3H0Q+D5wyRSXQUREmPoAWAbsqnveHcYNMbMNZrbVzLb29PRMaeFERFrJVAdA3lG0EX0Z3P0Wd1/j7msWLTqGM69ERGRCpjoAuoEVdc+XA7unuAwiIsLUB8A/A6vNbJWZtQEfAe6Z4jKIiAhTfB6Au5fN7D8CPwNSYJO7PzWVZRARkYzVnwV3sjGzHuAPTSxiIfDHE1ScV5NWXW/QumvdW0uj9X6tux/1IOpJHQDNMrOt7r5mussx1Vp1vUHrrnVvLc2ud+vcE1hEREZQAIiItKjYA+CW6S7ANGnV9Qate6tq1XVvar2jPgYgIiKNxV4DEBGRBqIMgFa65LSZrTCzLWb2jJk9ZWZXh/Hzzew+M9sR/h7nDSpfHcwsNbNfmdmPw/NVZvZoWO8fhBMOo2NmXWZ2p5k9G7b9O1pom/9t+K5vN7Pbzawj1u1uZpvMbK+Zba8bl7udLXNT2O/92szOPtryowuAFrzkdBn4tLu/AVgLfDKs70bgAXdfDTwQnsfoauCZuudfAr4c1ns/cOW0lGryfQX4J3d/PfBWss8g+m1uZsuAvwbWuPsZZCeUfoR4t/u3gItGjWu0ndcBq8NjA3Dz0RYeXQDQYpecdvcX3X1bGD5EtiNYRrbOt4XZbgMunZ4STh4zWw68D/hGeG7Au4E7wyyxrvcc4F3ArQDuPujuB2iBbR4UgE4zKwAzgBeJdLu7+8PAy6NGN9rOlwDf9swjQJeZLR1v+TEGwFEvOR0rM1sJnAU8Cixx9xchCwlg8fSVbNLcCHyW7A7fAAuAA+5eDs9j3fanAT3AN0Pz1zfMbCYtsM3d/QXgH4DnyXb8B4HHaY3tXtNoOx/3vi/GADjqJadjZGazgLuAv3H3V6a7PJPNzN4P7HX3x+tH58wa47YvAGcDN7v7WcARImzuyRPauy8BVgGnAjPJmj5Gi3G7H81xf/9jDICWu+S0mRXJdv7fdfcfhtF7atW/8HfvdJVvkpwLfMDMniNr5ns3WY2gKzQNQLzbvhvodvdHw/M7yQIh9m0O8OfA7929x91LwA+BP6M1tntNo+183Pu+GAOgpS45Hdq9bwWecfcb6ibdA6wPw+uBu6e6bJPJ3a9z9+XuvpJsGz/o7n8JbAE+HGaLbr0B3P0lYJeZnR5GXQA8TeTbPHgeWGtmM8J3v7bu0W/3Oo228z3Ax0JvoLXAwVpTUUPuHt0DuBj4F+C3wH+e7vJM8rq+k6ya92vgifC4mKw9/AFgR/g7f7rLOomfwXnAj8PwacBjwE7gfwLt012+SVrnM4GtYbv/L2Beq2xz4IvAs8B24H8A7bFud+B2smMdJbJf+Fc22s5kTUD/GPZ7T5L1lBp3+ToTWESkRcXYBCQiIsdAASAi0qIUACIiLUoBICLSohQAIiItSgEgItKiFAAiIi1KASAi0qL+P9UtB0RsFr8FAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.datasets import boston_housing\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def nnRegression():\n",
    "    nn = Sequential()\n",
    "    nn.add(Dense(output_dim=64,input_shape=(13,)))\n",
    "    nn.add(Activation('relu'))\n",
    "    nn.add(Dense(output_dim=16))\n",
    "    nn.add(Activation('relu'))\n",
    "    nn.add(Dense(output_dim=1))\n",
    "    \n",
    "    nn.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.boston_housing.load_data()\n",
    "\n",
    "    from keras.callbacks import EarlyStopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=50, verbose=2)\n",
    "    # 训练\n",
    "    history = nn.fit(x_train, y_train, epochs=300, batch_size=20, validation_data=(x_test, y_test), verbose=2, shuffle=False, callbacks=[early_stopping])\n",
    "    # loss曲线\n",
    "    plt.plot(history.history['loss'], label='train')\n",
    "    plt.plot(history.history['val_loss'], label='test')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "nnRegression()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 导入Fashion_MNIST数据集并可视化\n",
    "4. 构建全连接神经网络并使用导入的数据训练分类器\n",
    "5. 尝试改进神经网络的结构与训练方法提高模型性能"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_images = train_images.reshape([60000, 28*28])\n",
    "# test_images = test_images.reshape([10000, 28*28])\n",
    "# train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels, num_classes=10)\n",
    "test_labels = to_categorical(test_labels, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1efb5d6d518>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(Image.fromarray(train_images[0].reshape(28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " - 1s - loss: 12.2691 - acc: 0.2339\n",
      "Epoch 2/100\n",
      " - 1s - loss: 9.8254 - acc: 0.3866\n",
      "Epoch 3/100\n",
      " - 1s - loss: 8.0778 - acc: 0.4948\n",
      "Epoch 4/100\n",
      " - 1s - loss: 7.2674 - acc: 0.5460\n",
      "Epoch 5/100\n",
      " - 1s - loss: 6.8920 - acc: 0.5699\n",
      "Epoch 6/100\n",
      " - 1s - loss: 6.6043 - acc: 0.5884\n",
      "Epoch 7/100\n",
      " - 1s - loss: 6.4910 - acc: 0.5956\n",
      "Epoch 8/100\n",
      " - 1s - loss: 6.4689 - acc: 0.5972\n",
      "Epoch 9/100\n",
      " - 1s - loss: 6.3743 - acc: 0.6032\n",
      "Epoch 10/100\n",
      " - 1s - loss: 6.3558 - acc: 0.6045\n",
      "Epoch 11/100\n",
      " - 1s - loss: 6.3100 - acc: 0.6076\n",
      "Epoch 12/100\n",
      " - 1s - loss: 6.2502 - acc: 0.6111\n",
      "Epoch 13/100\n",
      " - 1s - loss: 6.2373 - acc: 0.6121\n",
      "Epoch 14/100\n",
      " - 1s - loss: 6.2493 - acc: 0.6114\n",
      "Epoch 15/100\n",
      " - 1s - loss: 6.2448 - acc: 0.6116\n",
      "Epoch 16/100\n",
      " - 1s - loss: 6.2251 - acc: 0.6128\n",
      "Epoch 17/100\n",
      " - 1s - loss: 6.1442 - acc: 0.6179\n",
      "Epoch 18/100\n",
      " - 1s - loss: 6.1479 - acc: 0.6179\n",
      "Epoch 19/100\n",
      " - 1s - loss: 6.1346 - acc: 0.6187\n",
      "Epoch 20/100\n",
      " - 1s - loss: 6.1689 - acc: 0.6164\n",
      "Epoch 21/100\n",
      " - 1s - loss: 6.1782 - acc: 0.6160\n",
      "Epoch 22/100\n",
      " - 1s - loss: 6.1328 - acc: 0.6188\n",
      "Epoch 23/100\n",
      " - 1s - loss: 6.0729 - acc: 0.6226\n",
      "Epoch 24/100\n",
      " - 1s - loss: 6.0025 - acc: 0.6272\n",
      "Epoch 25/100\n",
      " - 1s - loss: 6.0975 - acc: 0.6209\n",
      "Epoch 26/100\n",
      " - 1s - loss: 6.0462 - acc: 0.6243\n",
      "Epoch 27/100\n",
      " - 1s - loss: 6.0375 - acc: 0.6247\n",
      "Epoch 28/100\n",
      " - 1s - loss: 6.0857 - acc: 0.6218\n",
      "Epoch 29/100\n",
      " - 1s - loss: 6.0519 - acc: 0.6239\n",
      "Epoch 30/100\n",
      " - 1s - loss: 6.0073 - acc: 0.6267\n",
      "Epoch 31/100\n",
      " - 1s - loss: 6.0125 - acc: 0.6265\n",
      "Epoch 32/100\n",
      " - 1s - loss: 6.0272 - acc: 0.6254\n",
      "Epoch 33/100\n",
      " - 1s - loss: 6.0021 - acc: 0.6270\n",
      "Epoch 34/100\n",
      " - 1s - loss: 6.0380 - acc: 0.6247\n",
      "Epoch 35/100\n",
      " - 1s - loss: 6.0305 - acc: 0.6254\n",
      "Epoch 36/100\n",
      " - 1s - loss: 5.9593 - acc: 0.6298\n",
      "Epoch 37/100\n",
      " - 1s - loss: 6.0051 - acc: 0.6268\n",
      "Epoch 38/100\n",
      " - 1s - loss: 5.9637 - acc: 0.6293\n",
      "Epoch 39/100\n",
      " - 1s - loss: 6.0579 - acc: 0.6235\n",
      "Epoch 40/100\n",
      " - 1s - loss: 5.9677 - acc: 0.6293\n",
      "Epoch 41/100\n",
      " - 1s - loss: 6.0600 - acc: 0.6236\n",
      "Epoch 42/100\n",
      " - 1s - loss: 5.9811 - acc: 0.6285\n",
      "Epoch 43/100\n",
      " - 1s - loss: 5.9350 - acc: 0.6312\n",
      "Epoch 44/100\n",
      " - 1s - loss: 5.9988 - acc: 0.6273\n",
      "Epoch 45/100\n",
      " - 1s - loss: 5.9700 - acc: 0.6291\n",
      "Epoch 46/100\n",
      " - 1s - loss: 5.9281 - acc: 0.6317\n",
      "Epoch 47/100\n",
      " - 1s - loss: 5.9349 - acc: 0.6312\n",
      "Epoch 48/100\n",
      " - 1s - loss: 5.9480 - acc: 0.6305\n",
      "Epoch 49/100\n",
      " - 1s - loss: 5.9453 - acc: 0.6307\n",
      "Epoch 50/100\n",
      " - 1s - loss: 5.9914 - acc: 0.6278\n",
      "Epoch 51/100\n",
      " - 1s - loss: 5.9626 - acc: 0.6296\n",
      "Epoch 52/100\n",
      " - 1s - loss: 5.9215 - acc: 0.6322\n",
      "Epoch 53/100\n",
      " - 1s - loss: 5.9480 - acc: 0.6304\n",
      "Epoch 54/100\n",
      " - 1s - loss: 5.9427 - acc: 0.6307\n",
      "Epoch 55/100\n",
      " - 1s - loss: 5.9465 - acc: 0.6306\n",
      "Epoch 56/100\n",
      " - 1s - loss: 5.9289 - acc: 0.6316\n",
      "Epoch 57/100\n",
      " - 1s - loss: 5.9502 - acc: 0.6304\n",
      "Epoch 58/100\n",
      " - 1s - loss: 5.9519 - acc: 0.6304\n",
      "Epoch 59/100\n",
      " - 1s - loss: 5.9023 - acc: 0.6334\n",
      "Epoch 60/100\n",
      " - 1s - loss: 5.9031 - acc: 0.6333\n",
      "Epoch 61/100\n",
      " - 1s - loss: 6.0322 - acc: 0.6254\n",
      "Epoch 62/100\n",
      " - 1s - loss: 5.8921 - acc: 0.6340\n",
      "Epoch 63/100\n",
      " - 1s - loss: 5.8533 - acc: 0.6364\n",
      "Epoch 64/100\n",
      " - 1s - loss: 5.8627 - acc: 0.6359\n",
      "Epoch 65/100\n",
      " - 1s - loss: 5.8577 - acc: 0.6363\n",
      "Epoch 66/100\n",
      " - 1s - loss: 5.8818 - acc: 0.6344\n",
      "Epoch 67/100\n",
      " - 1s - loss: 5.8682 - acc: 0.6356\n",
      "Epoch 68/100\n",
      " - 1s - loss: 5.8349 - acc: 0.6377\n",
      "Epoch 69/100\n",
      " - 1s - loss: 5.8779 - acc: 0.6351\n",
      "Epoch 70/100\n",
      " - 1s - loss: 5.8712 - acc: 0.6354\n",
      "Epoch 71/100\n",
      " - 1s - loss: 5.8376 - acc: 0.6375\n",
      "Epoch 72/100\n",
      " - 1s - loss: 5.9063 - acc: 0.6333\n",
      "Epoch 73/100\n",
      " - 1s - loss: 5.9213 - acc: 0.6323\n",
      "Epoch 74/100\n",
      " - 1s - loss: 5.9258 - acc: 0.6321\n",
      "Epoch 75/100\n",
      " - 1s - loss: 5.8587 - acc: 0.6361\n",
      "Epoch 76/100\n",
      " - 1s - loss: 5.8528 - acc: 0.6366\n",
      "Epoch 77/100\n",
      " - 1s - loss: 5.8931 - acc: 0.6341\n",
      "Epoch 78/100\n",
      " - 1s - loss: 5.9491 - acc: 0.6306\n",
      "Epoch 79/100\n",
      " - 1s - loss: 5.8661 - acc: 0.6358\n",
      "Epoch 80/100\n",
      " - 1s - loss: 5.9117 - acc: 0.6328\n",
      "Epoch 81/100\n",
      " - 1s - loss: 5.9621 - acc: 0.6299\n",
      "Epoch 82/100\n",
      " - 1s - loss: 5.9076 - acc: 0.6332\n",
      "Epoch 83/100\n",
      " - 1s - loss: 5.8732 - acc: 0.6353\n",
      "Epoch 84/100\n",
      " - 1s - loss: 5.8771 - acc: 0.6351\n",
      "Epoch 85/100\n",
      " - 1s - loss: 5.8413 - acc: 0.6372\n",
      "Epoch 86/100\n",
      " - 1s - loss: 5.8804 - acc: 0.6349\n",
      "Epoch 87/100\n",
      " - 1s - loss: 5.8546 - acc: 0.6365\n",
      "Epoch 88/100\n",
      " - 1s - loss: 5.8869 - acc: 0.6345\n",
      "Epoch 89/100\n",
      " - 1s - loss: 5.8415 - acc: 0.6372\n",
      "Epoch 90/100\n",
      " - 1s - loss: 5.8270 - acc: 0.6383\n",
      "Epoch 91/100\n",
      " - 1s - loss: 5.8622 - acc: 0.6360\n",
      "Epoch 92/100\n",
      " - 1s - loss: 5.8434 - acc: 0.6371\n",
      "Epoch 93/100\n",
      " - 1s - loss: 5.8207 - acc: 0.6386\n",
      "Epoch 94/100\n",
      " - 1s - loss: 5.8014 - acc: 0.6398\n",
      "Epoch 95/100\n",
      " - 1s - loss: 5.8421 - acc: 0.6371\n",
      "Epoch 96/100\n",
      " - 1s - loss: 5.7931 - acc: 0.6403\n",
      "Epoch 97/100\n",
      " - 1s - loss: 5.8098 - acc: 0.6392\n",
      "Epoch 98/100\n",
      " - 1s - loss: 5.8308 - acc: 0.6379\n",
      "Epoch 99/100\n",
      " - 1s - loss: 5.8192 - acc: 0.6386\n",
      "Epoch 100/100\n",
      " - 1s - loss: 5.8025 - acc: 0.6396\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 5.739430226898193\n",
      "Test top 1 accuracy: 0.6437\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(128, activation='relu',kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(64, activation='relu', kernel_initializer='glorot_uniform'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(100, activation='relu',kernel_initializer = 'glorot_uniform'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(10, activation='softmax',kernel_initializer = 'glorot_uniform'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer=\"rmsprop\",metrics=['accuracy'])\n",
    "history = model.fit(train_images, train_labels,batch_size=256,epochs=100,verbose=2)\n",
    "\n",
    "# print(model.summary())\n",
    "plt.plot(history.history['loss'])\n",
    "\n",
    "plt.title(\"model loss\")\n",
    "\n",
    "plt.ylabel(\"loss\")\n",
    "\n",
    "plt.xlabel(\"epoch\")\n",
    "\n",
    "plt.legend([\"train\"],loc=\"upper left\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "score = model.evaluate(test_images, test_labels, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test top 1 accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydp-notebook",
   "language": "python",
   "name": "pydp-notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
